# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# source: cobaltspeech/sentimo/v1/sentimo.proto
# Protobuf Python Version: 5.26.1
"""Generated protocol buffer code."""
from google.protobuf import descriptor as _descriptor
from google.protobuf import descriptor_pool as _descriptor_pool
from google.protobuf import symbol_database as _symbol_database
from google.protobuf.internal import builder as _builder
# @@protoc_insertion_point(imports)

_sym_db = _symbol_database.Default()


from cobaltspeech.transcribe.v5 import transcribe_pb2 as cobaltspeech_dot_transcribe_dot_v5_dot_transcribe__pb2


DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n%cobaltspeech/sentimo/v1/sentimo.proto\x12\x17\x63obaltspeech.sentimo.v1\x1a+cobaltspeech/transcribe/v5/transcribe.proto\"\x10\n\x0eVersionRequest\")\n\x0fVersionResponse\x12\x16\n\x06server\x18\x01 \x01(\tR\x06server\"\x13\n\x11ListModelsRequest\"L\n\x12ListModelsResponse\x12\x36\n\x06models\x18\x01 \x03(\x0b\x32\x1e.cobaltspeech.sentimo.v1.ModelR\x06models\"\xa7\x01\n\x19StreamingRecognizeRequest\x12\x39\n\x06\x63onfig\x18\x01 \x01(\x0b\x32\x1f.cobaltspeech.sentimo.v1.ConfigH\x00R\x06\x63onfig\x12\x44\n\x05\x61udio\x18\x02 \x01(\x0b\x32,.cobaltspeech.transcribe.v5.RecognitionAudioH\x00R\x05\x61udioB\t\n\x07request\"\xfc\x01\n\x1aStreamingRecognizeResponse\x12V\n\ntranscribe\x18\x01 \x01(\x0b\x32\x36.cobaltspeech.transcribe.v5.StreamingRecognizeResponseR\ntranscribe\x12\x42\n\x07sentimo\x18\x02 \x01(\x0b\x32(.cobaltspeech.sentimo.v1.SentimoResponseR\x07sentimo\x12\x42\n\x05\x65rror\x18\x03 \x01(\x0b\x32,.cobaltspeech.transcribe.v5.RecognitionErrorR\x05\x65rror\"\x81\x01\n\x06\x43onfig\x12\x19\n\x08model_id\x18\x01 \x01(\tR\x07modelId\x12\\\n\x12recognition_config\x18\x02 \x01(\x0b\x32-.cobaltspeech.transcribe.v5.RecognitionConfigR\x11recognitionConfig\"u\n\x05Model\x12\x0e\n\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n\x04name\x18\x02 \x01(\tR\x04name\x12H\n\nattributes\x18\x03 \x01(\x0b\x32(.cobaltspeech.sentimo.v1.ModelAttributesR\nattributes\"y\n\x0fModelAttributes\x12!\n\x0c\x63lass_labels\x18\x01 \x03(\tR\x0b\x63lassLabels\x12\x43\n\x1e\x61vailable_transcribe_model_ids\x18\x02 \x03(\tR\x1b\x61vailableTranscribeModelIds\"\x9d\x01\n\x0fSentimoResponse\x12\x45\n\x0bpredictions\x18\x01 \x03(\x0b\x32#.cobaltspeech.sentimo.v1.PredictionR\x0bpredictions\x12\"\n\rstart_time_ms\x18\x02 \x01(\x04R\x0bstartTimeMs\x12\x1f\n\x0b\x64uration_ms\x18\x03 \x01(\x04R\ndurationMs\"D\n\nPrediction\x12\x14\n\x05label\x18\x01 \x01(\tR\x05label\x12 \n\x0bprobability\x18\x02 \x01(\x02R\x0bprobability2\xdf\x02\n\x0eSentimoService\x12^\n\x07Version\x12\'.cobaltspeech.sentimo.v1.VersionRequest\x1a(.cobaltspeech.sentimo.v1.VersionResponse\"\x00\x12g\n\nListModels\x12*.cobaltspeech.sentimo.v1.ListModelsRequest\x1a+.cobaltspeech.sentimo.v1.ListModelsResponse\"\x00\x12\x83\x01\n\x12StreamingRecognize\x12\x32.cobaltspeech.sentimo.v1.StreamingRecognizeRequest\x1a\x33.cobaltspeech.sentimo.v1.StreamingRecognizeResponse\"\x00(\x01\x30\x01\x42\xf0\x01\n\x1b\x63om.cobaltspeech.sentimo.v1B\x0cSentimoProtoP\x01ZEgithub.com/cobaltspeech/go-genproto/cobaltspeech/sentimo/v1;sentimov1\xa2\x02\x03\x43SX\xaa\x02\x17\x43obaltspeech.Sentimo.V1\xca\x02\x17\x43obaltspeech\\Sentimo\\V1\xe2\x02#Cobaltspeech\\Sentimo\\V1\\GPBMetadata\xea\x02\x19\x43obaltspeech::Sentimo::V1b\x06proto3')

_globals = globals()
_builder.BuildMessageAndEnumDescriptors(DESCRIPTOR, _globals)
_builder.BuildTopDescriptorsAndMessages(DESCRIPTOR, 'cobaltspeech.sentimo.v1.sentimo_pb2', _globals)
if not _descriptor._USE_C_DESCRIPTORS:
  _globals['DESCRIPTOR']._loaded_options = None
  _globals['DESCRIPTOR']._serialized_options = b'\n\033com.cobaltspeech.sentimo.v1B\014SentimoProtoP\001ZEgithub.com/cobaltspeech/go-genproto/cobaltspeech/sentimo/v1;sentimov1\242\002\003CSX\252\002\027Cobaltspeech.Sentimo.V1\312\002\027Cobaltspeech\\Sentimo\\V1\342\002#Cobaltspeech\\Sentimo\\V1\\GPBMetadata\352\002\031Cobaltspeech::Sentimo::V1'
  _globals['_VERSIONREQUEST']._serialized_start=111
  _globals['_VERSIONREQUEST']._serialized_end=127
  _globals['_VERSIONRESPONSE']._serialized_start=129
  _globals['_VERSIONRESPONSE']._serialized_end=170
  _globals['_LISTMODELSREQUEST']._serialized_start=172
  _globals['_LISTMODELSREQUEST']._serialized_end=191
  _globals['_LISTMODELSRESPONSE']._serialized_start=193
  _globals['_LISTMODELSRESPONSE']._serialized_end=269
  _globals['_STREAMINGRECOGNIZEREQUEST']._serialized_start=272
  _globals['_STREAMINGRECOGNIZEREQUEST']._serialized_end=439
  _globals['_STREAMINGRECOGNIZERESPONSE']._serialized_start=442
  _globals['_STREAMINGRECOGNIZERESPONSE']._serialized_end=694
  _globals['_CONFIG']._serialized_start=697
  _globals['_CONFIG']._serialized_end=826
  _globals['_MODEL']._serialized_start=828
  _globals['_MODEL']._serialized_end=945
  _globals['_MODELATTRIBUTES']._serialized_start=947
  _globals['_MODELATTRIBUTES']._serialized_end=1068
  _globals['_SENTIMORESPONSE']._serialized_start=1071
  _globals['_SENTIMORESPONSE']._serialized_end=1228
  _globals['_PREDICTION']._serialized_start=1230
  _globals['_PREDICTION']._serialized_end=1298
  _globals['_SENTIMOSERVICE']._serialized_start=1301
  _globals['_SENTIMOSERVICE']._serialized_end=1652
# @@protoc_insertion_point(module_scope)
